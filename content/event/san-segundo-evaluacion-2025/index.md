
+++
title = "Evaluación de la percepción humana en la detección de deepfakes de audio"
date = 2025-05-24
authors = ["Eugenia San Segundo", "Aurora López-Jareño"]
publication_types = ["1"]
all_day = true
abstract = "Los *deepfakes* son voces sintéticas generadas por modelos de aprendizaje profundo. Su uso para difamar a figuras públicas, o para hacerles emitir mensajes falsos, es cada vez más frecuente. Esto dificulta la distinción entre noticias reales y falsas, erosionando la confianza en los medios. En el ámbito de la fonética aplicada, escasean los estudios perceptivos que investiguen la capacidad de distinguir voces reales de *deepfakes*. En Mai et al. (2023) se muestra que los humanos pueden detectar *deepfakes* perceptivamente, independientemente de si las grabaciones son en inglés o mandarín. En nuestro estudio, diseñamos un experimento perceptivo con PsychoPy usando dos corpus de voces de celebridades: VoxCeleb-ESP (Labrador et al., 2023) para el español y EACELEB (Caulley et al., 2022) para el japonés. En ambos casos generamos sus clones sintéticos con ElevenLabs. También usamos MLAAD (Müller et al., 2024) para obtener voces sintéticas en otro estilo de habla: lectura (en español y japonés). Nuestro test perceptivo fue realizado por oyentes de dos lenguas maternas distintas: español y japonés. Así, seguimos la línea del trabajo de Mai et al. (2023), al tiempo que exploramos nuevas variables como el estilo de habla y la familiaridad del oyente con el hablante."
featured = true
event = "*XXXVII Congreso de la Confederación Académica Nipona, Española y Latinoamericana, CANELA*"
location = "University of the Ryukyus, Okinawa, Japan"
+++











